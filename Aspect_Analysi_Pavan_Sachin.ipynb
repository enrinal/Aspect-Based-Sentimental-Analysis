{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing all the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating a Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Aspect_Term</th>\n",
       "      <th>Term_Location</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3121_0</th>\n",
       "      <td>But the staff was so horrible to us.</td>\n",
       "      <td>staff</td>\n",
       "      <td>8--13</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2777_0</th>\n",
       "      <td>To be completely fair[comma] the only redeemin...</td>\n",
       "      <td>food</td>\n",
       "      <td>57--61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634_0</th>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>food</td>\n",
       "      <td>4--8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634_1</th>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>kitchen</td>\n",
       "      <td>55--62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634_2</th>\n",
       "      <td>The food is uniformly exceptional[comma] with ...</td>\n",
       "      <td>menu</td>\n",
       "      <td>141--145</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Text Aspect_Term  \\\n",
       "ID                                                                      \n",
       "3121_0               But the staff was so horrible to us.       staff   \n",
       "2777_0  To be completely fair[comma] the only redeemin...        food   \n",
       "1634_0  The food is uniformly exceptional[comma] with ...        food   \n",
       "1634_1  The food is uniformly exceptional[comma] with ...     kitchen   \n",
       "1634_2  The food is uniformly exceptional[comma] with ...        menu   \n",
       "\n",
       "       Term_Location  Class  \n",
       "ID                           \n",
       "3121_0         8--13     -1  \n",
       "2777_0        57--61      1  \n",
       "1634_0          4--8      1  \n",
       "1634_1        55--62      1  \n",
       "1634_2      141--145      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\".\\data_2.csv\", skiprows =1, names = ['ID', 'Text', 'Aspect_Term', 'Term_Location', 'Class'], index_col = 'ID')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Function to Preprocess the Data (Removing the StopWords and Performing Stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import *\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "but = {'any', 'also', 'but', 'that' , 'hence', 'therefore', 'if', 'only', 'so'}\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('comma')\n",
    "\n",
    "def text_process(mess,aspect_term,stem):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    messg=str(mess)\n",
    "    messg = messg.lower()\n",
    "    aspect = str(aspect_term).lower()\n",
    "    aspect = aspect.split()\n",
    "    sentence = re.sub('\\W+', ' ', messg)\n",
    "    array = sentence.split()\n",
    "    pos = 0\n",
    "    a_pos = 0\n",
    "    for i,val in enumerate(array):\n",
    "        if val in but:\n",
    "            pos = i\n",
    "        if val in aspect:\n",
    "            a_pos = i\n",
    "\n",
    "    if pos < a_pos:\n",
    "        messg = array[pos+1:a_pos+len(aspect)+1]\n",
    "    else:\n",
    "        messg = array[:a_pos + len(aspect) + 1]\n",
    "    \n",
    "    textt = word_tokenize(' '.join(messg))\n",
    "#     print textt\n",
    "    filtered_sentence = [w for w in textt if not w in stop_words]\n",
    "#     print filtered_sentence\n",
    "    \n",
    "    if stem:\n",
    "        ar1 = []\n",
    "        ps = PorterStemmer()\n",
    "        lanc = LancasterStemmer()\n",
    "        lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "        sno = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "        words = [sno.stem(w) for w in filtered_sentence]\n",
    "        filtered_sentence = [ps.stem(w) for w in words]\n",
    "        \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_train_reviews=[] \n",
    "for i in xrange(0,len(df)):\n",
    "    clean_train_reviews.append(\" \".join(text_process(df[\"Text\"][i],df[\"Aspect_Term\"][i],False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data after the Preprocesssing Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "staff\n"
     ]
    }
   ],
   "source": [
    "print clean_train_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Creating the Feature Set and Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_train_reviews\n",
    "y = df.Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Instantiating the Vector and Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vect = CountVectorizer()\n",
    "# vect.fit(X)\n",
    "# vect.get_feature_names()\n",
    "# simple_train_dtm = vect.transform(X)\n",
    "# print simple_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(simple_train_dtm.toarray(), columns=vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# vect = CountVectorizer(stop_words = 'english', lowercase=True)\n",
    "vect = TfidfVectorizer( ngram_range=(1,3), min_df=1,strip_accents='unicode')\n",
    "X_dtm = vect.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_clf = Pipeline([('vect', TfidfVectorizer(ngram_range=(1,5),min_df=1,strip_accents='unicode')),\n",
    "#                      #('feature_selection', SelectFromModel(svm.LinearSVC(penalty=\"l1\",dual=False))),\n",
    "#                      #('feature_selection', SelectFromModel(RandomForestClassifier())),\n",
    "#                      ('clf', svm.LinearSVC())\n",
    "#                     ])\n",
    "\n",
    "\n",
    "# text_clf = text_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into training and testing sets\n",
    "# from sklearn.cross_validation import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vect.fit(X_train)\n",
    "# X_train_dtm = vect.fit_transform(X_train)\n",
    "# X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "\n",
    "def classification_report_with_accuracy_score(y_true, y_pred):\n",
    "    print classification_report(y_true, y_pred) # print classification report\n",
    "    return accuracy_score(y_true, y_pred) # return accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.23      0.36        81\n",
      "          0       0.36      0.06      0.11        64\n",
      "          1       0.65      0.98      0.78       217\n",
      "\n",
      "avg / total       0.62      0.65      0.57       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.47      0.17      0.25        81\n",
      "          0       0.44      0.12      0.20        64\n",
      "          1       0.64      0.93      0.76       217\n",
      "\n",
      "avg / total       0.57      0.62      0.54       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.46      0.14      0.21        81\n",
      "          0       0.32      0.11      0.16        64\n",
      "          1       0.66      0.95      0.78       217\n",
      "\n",
      "avg / total       0.55      0.62      0.54       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.50      0.11      0.18        81\n",
      "          0       0.33      0.08      0.13        63\n",
      "          1       0.62      0.94      0.74       217\n",
      "\n",
      "avg / total       0.54      0.60      0.51       361\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.57      0.15      0.24        81\n",
      "          0       0.62      0.13      0.21        63\n",
      "          1       0.63      0.96      0.76       216\n",
      "\n",
      "avg / total       0.62      0.63      0.55       360\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.44      0.14      0.21        80\n",
      "          0       0.46      0.21      0.29        63\n",
      "          1       0.65      0.92      0.76       216\n",
      "\n",
      "avg / total       0.57      0.62      0.56       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.23      0.09      0.13        80\n",
      "          0       0.75      0.05      0.09        63\n",
      "          1       0.63      0.95      0.76       216\n",
      "\n",
      "avg / total       0.56      0.60      0.50       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.43      0.12      0.19        80\n",
      "          0       0.22      0.06      0.10        63\n",
      "          1       0.64      0.94      0.76       216\n",
      "\n",
      "avg / total       0.52      0.61      0.52       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.44      0.23      0.30        80\n",
      "          0       0.27      0.10      0.14        63\n",
      "          1       0.66      0.91      0.77       216\n",
      "\n",
      "avg / total       0.54      0.61      0.55       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.59      0.16      0.25        80\n",
      "          0       0.25      0.05      0.08        63\n",
      "          1       0.63      0.95      0.76       216\n",
      "\n",
      "avg / total       0.56      0.62      0.53       359\n",
      "\n",
      "[0.64917127 0.6160221  0.62154696 0.60110803 0.63055556 0.62116992\n",
      " 0.59888579 0.60724234 0.61281337 0.6183844 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "nested_score = cross_val_score(clf , X_dtm , y, cv =10, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print nested_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6176899742015285\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC(kernel='linear')\n",
    "scores = cross_val_score(clf , X_dtm , y, cv =10 , scoring = 'accuracy')\n",
    "print scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.50      0.05      0.09        81\n",
      "          0       0.00      0.00      0.00        64\n",
      "          1       0.61      1.00      0.76       217\n",
      "\n",
      "avg / total       0.48      0.61      0.48       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.50      0.01      0.02        81\n",
      "          0       0.00      0.00      0.00        64\n",
      "          1       0.60      1.00      0.75       217\n",
      "\n",
      "avg / total       0.47      0.60      0.46       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.56      0.06      0.11        81\n",
      "          0       0.00      0.00      0.00        64\n",
      "          1       0.62      0.99      0.76       217\n",
      "\n",
      "avg / total       0.49      0.61      0.48       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.33      0.02      0.05        81\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.61      1.00      0.76       217\n",
      "\n",
      "avg / total       0.44      0.60      0.46       361\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.60      0.04      0.07        81\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.61      1.00      0.75       216\n",
      "\n",
      "avg / total       0.50      0.61      0.47       360\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.00      0.00      0.00        80\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.60      0.98      0.74       216\n",
      "\n",
      "avg / total       0.36      0.59      0.45       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.17      0.01      0.02        80\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.62      1.00      0.76       216\n",
      "\n",
      "avg / total       0.41      0.60      0.46       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.50      0.01      0.02        80\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.61      1.00      0.76       216\n",
      "\n",
      "avg / total       0.48      0.60      0.46       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.04      0.07        80\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.61      1.00      0.76       216\n",
      "\n",
      "avg / total       0.53      0.61      0.47       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.50      0.01      0.02        80\n",
      "          0       0.00      0.00      0.00        63\n",
      "          1       0.61      1.00      0.75       216\n",
      "\n",
      "avg / total       0.48      0.60      0.46       359\n",
      "\n",
      "[0.60354467]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pavan\\Miniconda3\\envs\\py27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "nested_score = cross_val_score(clf , X_dtm , y, cv =10, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print nested_score.mean(keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.46      0.32      0.38        81\n",
      "          0       0.15      0.06      0.09        64\n",
      "          1       0.65      0.84      0.73       217\n",
      "\n",
      "avg / total       0.52      0.59      0.54       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.35      0.36      0.35        81\n",
      "          0       0.44      0.23      0.31        64\n",
      "          1       0.67      0.75      0.71       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.37      0.49      0.42        81\n",
      "          0       0.29      0.11      0.16        64\n",
      "          1       0.70      0.74      0.72       217\n",
      "\n",
      "avg / total       0.55      0.57      0.55       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.35      0.11      0.17        81\n",
      "          0       0.32      0.11      0.16        63\n",
      "          1       0.64      0.92      0.75       217\n",
      "\n",
      "avg / total       0.52      0.60      0.52       361\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.42      0.27      0.33        81\n",
      "          0       0.44      0.11      0.18        63\n",
      "          1       0.65      0.88      0.75       216\n",
      "\n",
      "avg / total       0.56      0.61      0.55       360\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.32      0.26      0.29        80\n",
      "          0       0.52      0.17      0.26        63\n",
      "          1       0.66      0.83      0.73       216\n",
      "\n",
      "avg / total       0.56      0.59      0.55       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.23      0.17      0.20        80\n",
      "          0       0.27      0.13      0.17        63\n",
      "          1       0.62      0.77      0.69       216\n",
      "\n",
      "avg / total       0.47      0.52      0.49       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.26      0.23      0.24        80\n",
      "          0       0.19      0.05      0.08        63\n",
      "          1       0.63      0.80      0.70       216\n",
      "\n",
      "avg / total       0.47      0.54      0.49       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.38      0.36      0.37        80\n",
      "          0       0.19      0.10      0.13        63\n",
      "          1       0.67      0.79      0.73       216\n",
      "\n",
      "avg / total       0.52      0.57      0.54       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.39      0.21      0.27        80\n",
      "          0       0.35      0.13      0.19        63\n",
      "          1       0.66      0.90      0.76       216\n",
      "\n",
      "avg / total       0.55      0.61      0.55       359\n",
      "\n",
      "[0.58563536 0.5718232  0.5718232  0.59556787 0.60555556 0.58774373\n",
      " 0.52367688 0.54038997 0.57103064 0.61002786]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "nested_score = cross_val_score(clf , X_dtm , y, cv =10, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print nested_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.34      0.19      0.24        81\n",
      "          0       0.27      0.05      0.08        64\n",
      "          1       0.65      0.92      0.76       217\n",
      "\n",
      "avg / total       0.51      0.60      0.52       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.37      0.17      0.24        81\n",
      "          0       0.38      0.09      0.15        64\n",
      "          1       0.65      0.93      0.77       217\n",
      "\n",
      "avg / total       0.54      0.61      0.54       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.39      0.16      0.23        81\n",
      "          0       0.45      0.14      0.21        64\n",
      "          1       0.66      0.94      0.77       217\n",
      "\n",
      "avg / total       0.56      0.62      0.55       362\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.28      0.10      0.15        81\n",
      "          0       0.23      0.05      0.08        63\n",
      "          1       0.61      0.90      0.73       217\n",
      "\n",
      "avg / total       0.47      0.57      0.49       361\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.31      0.19      0.23        81\n",
      "          0       0.50      0.10      0.16        63\n",
      "          1       0.65      0.90      0.75       216\n",
      "\n",
      "avg / total       0.55      0.60      0.53       360\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.44      0.21      0.29        80\n",
      "          0       0.50      0.19      0.28        63\n",
      "          1       0.67      0.91      0.77       216\n",
      "\n",
      "avg / total       0.59      0.63      0.58       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.21      0.12      0.16        80\n",
      "          0       0.35      0.17      0.23        63\n",
      "          1       0.65      0.84      0.73       216\n",
      "\n",
      "avg / total       0.50      0.57      0.52       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.32      0.19      0.24        80\n",
      "          0       0.22      0.06      0.10        63\n",
      "          1       0.67      0.91      0.77       216\n",
      "\n",
      "avg / total       0.51      0.60      0.53       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.36      0.25      0.29        80\n",
      "          0       0.36      0.14      0.20        63\n",
      "          1       0.69      0.89      0.78       216\n",
      "\n",
      "avg / total       0.56      0.62      0.57       359\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.48      0.30      0.37        80\n",
      "          0       0.33      0.06      0.11        63\n",
      "          1       0.68      0.94      0.79       216\n",
      "\n",
      "avg / total       0.57      0.64      0.57       359\n",
      "\n",
      "[0.60550459]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1)\n",
    "nested_score = cross_val_score(clf , X_dtm , y, cv =10, scoring=make_scorer(classification_report_with_accuracy_score))\n",
    "print nested_score.mean(keepdims=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
